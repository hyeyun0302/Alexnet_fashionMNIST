{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMIUwUemMSBEfbZaRfiyeMg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hyeyun0302/Alexnet_fashionMNIST/blob/main/AlexNet_FashionMNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "b4tGxJGbRuej"
      },
      "outputs": [],
      "source": [
        "import os # 파이썬을 이용해 파일을 복사하거나 디렉터리를 생성하고 특정 디렉터리 내의 파일 목록을 구하고자 할 때 사용\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torchvision # torchvision package : 컴퓨터 비전을 위한 유명 데이터셋, 모델 아키텍처, 이미지 변형등을 포함\n",
        "import torch.nn as nn # nn : neural netwroks (define class) attribute를 활용해 state를 저장하고 활용\n",
        "import torch.optim as optim # 최적화 알고리즘\n",
        "import torch.nn.functional as F # (define function) 인스턴스화 시킬 필요없이 사용 가능\n",
        "from PIL import Image\n",
        "from torchvision import transforms, datasets # transforms : 데이터를 조작하고 학습에 적합하게 만듦.\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "# dataset : 샘플과 정답(label)을 저장\n",
        "# DataLoader : Dataset 을 샘플에 쉽게 접근할 수 있도록 순회 가능한 객체(iterable)로 감싼다."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 10 # 훈련 반복수\n",
        "batch_size = 512 # 배치 크기\n",
        "\n",
        "device = (\"cuda\" if torch.cuda.is_available() else \"cpu\") # device 정의\n",
        "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
        "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot'] # 총 10개의 클래스\n",
        "\n",
        "print(torch.__version__)\n",
        "print(device)\n",
        "\n",
        "# 결과\n",
        "# 1.10.0+cu111\n",
        "# cuda"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Dwb6C13RweI",
        "outputId": "cf0efe74-55b8-453a-c2e9-e820b7d55b0a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.0.1+cu118\n",
            "cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize(227), # Compose : transforms 리스트 구성\n",
        "    # 227x227 : input image(in alexnet) but fashionMNIST's input image : 28x28\n",
        "    transforms.ToTensor()]) # ToTensor : PIL image or numpy.ndarray를 tensor로 바꿈\n",
        "\n",
        "training_data = datasets.FashionMNIST(\n",
        "    root=\"data\", # data가 저장될 경로(path)\n",
        "    train=True, # training dataset\n",
        "    download=True, # 인터넷으로부터 데이터 다운\n",
        "    transform=transform # feature 및 label 변환(transformation) 지정\n",
        ")\n",
        "\n",
        "validation_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=False, # test dataset\n",
        "    download=True,\n",
        "    transform=transform\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FRlaNbolRyjM",
        "outputId": "a266792e-cc4b-462e-da8a-75a589b998a3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26421880/26421880 [00:01<00:00, 19530071.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/train-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29515/29515 [00:00<00:00, 294944.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4422102/4422102 [00:00<00:00, 5509813.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5148/5148 [00:00<00:00, 23780040.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# (class) DataLoader(dataset, batch_size, shuffle, ...)\n",
        "training_loader = DataLoader(training_data, batch_size=64, shuffle=True)\n",
        "validation_loader = DataLoader(validation_data, batch_size=64, shuffle=True)"
      ],
      "metadata": {
        "id": "153U5U2-Ryqp"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "알렉스넷(AlexNet) 모델 구현"
      ],
      "metadata": {
        "id": "TA4CTgnnSELm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class fashion_mnist_alexnet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Sequential(\n",
        "\n",
        "            nn.Conv2d(in_channels=1, out_channels=96, kernel_size=11, stride=4, padding=0),\n",
        "            # 4D tensor : [number_of_kernels, input_channels, kernel_width, kernel_height]\n",
        "            # = 96x1x11x11\n",
        "            # input size : 1x227x227\n",
        "            # input size 정의 : (N, C, H, W) or (C, H, W)\n",
        "            # W' = (W-F+2P)/S + 1\n",
        "            # 55x55x96 feature map 생성 (55는 (227-11+1)/4)\n",
        "            # 최종적으로 227 -> 55\n",
        "            nn.ReLU(), # 96x55x55\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2)\n",
        "            # 55 -> (55-3+1)/2 = 26.5 = 27\n",
        "            # 96x27x27 feature map 생성\n",
        "\n",
        "        )\n",
        "        self.conv2 = nn.Sequential(\n",
        "            nn.Conv2d(96, 256, 5, 1, 2), # in_channels: 96, out_channels: 256, kernel_size=5x5, stride=1, padding=2\n",
        "            # kernel 수 = 48x5x5 (드롭아웃을 사용했기 때문에 96/2=48) 형태의 256개\n",
        "            # 256x27x27\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(3, 2) # 27 -> 13\n",
        "            # 256x13x13\n",
        "        )\n",
        "        self.conv3 = nn.Sequential(\n",
        "            nn.Conv2d(256, 384, 3, 1, 1),\n",
        "            nn.ReLU() # 13 유지\n",
        "            # 384x13x13\n",
        "        )\n",
        "        self.conv4 = nn.Sequential(\n",
        "            nn.Conv2d(384, 384, 3, 1, 1),\n",
        "            nn.ReLU() # 13 유지\n",
        "            # 384x13x13\n",
        "        )\n",
        "        self.conv5 = nn.Sequential(\n",
        "            nn.Conv2d(384, 256, 3, 1, 1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(3, 2) # 13 -> 6\n",
        "            # 256x6x6\n",
        "        )\n",
        "\n",
        "        self.fc1 = nn.Linear(256 * 6 * 6, 4096)\n",
        "        self.fc2 = nn.Linear(4096, 4096)\n",
        "        self.fc3 = nn.Linear(4096, 10)\n",
        "\n",
        "    def forward(self, x): # input size = 3x227x227\n",
        "        out = self.conv1(x)\n",
        "        out = self.conv2(out)\n",
        "        out = self.conv3(out)\n",
        "        out = self.conv4(out)\n",
        "        out = self.conv5(out) # 64x4096x1x1\n",
        "        out = out.view(out.size(0), -1) # 64x4096\n",
        "\n",
        "        out = F.relu(self.fc1(out))\n",
        "        out = F.dropout(out, 0.5)\n",
        "        out = F.relu(self.fc2(out))\n",
        "        out = F.dropout(out, 0.5)\n",
        "        out = self.fc3(out)\n",
        "        out = F.log_softmax(out, dim=1)\n",
        "\n",
        "        return out"
      ],
      "metadata": {
        "id": "0rn1vclSRyw7"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "모델 생성"
      ],
      "metadata": {
        "id": "cmZ986q3SVIQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = fashion_mnist_alexnet().to(device) # to()로 모델에 gpu 사용\n",
        "criterion = F.nll_loss # nll_loss : negative log likelihood loss\n",
        "optimizer = optim.Adam(model.parameters()) # model(신경망) 파라미터를 optimizer에 전달해줄 때 nn.Module의 parameters() 메소드를 사용"
      ],
      "metadata": {
        "id": "v80OIdpiRyzH"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchsummary import summary as summary_\n",
        "\n",
        "summary_(model, (1,227,227), batch_size)\n",
        "# summary_: (model, input_size, batch_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yWbz82zzSl4S",
        "outputId": "a7bdbee2-df4c-410f-b05e-d9c11827d86a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1          [512, 96, 55, 55]          11,712\n",
            "              ReLU-2          [512, 96, 55, 55]               0\n",
            "         MaxPool2d-3          [512, 96, 27, 27]               0\n",
            "            Conv2d-4         [512, 256, 27, 27]         614,656\n",
            "              ReLU-5         [512, 256, 27, 27]               0\n",
            "         MaxPool2d-6         [512, 256, 13, 13]               0\n",
            "            Conv2d-7         [512, 384, 13, 13]         885,120\n",
            "              ReLU-8         [512, 384, 13, 13]               0\n",
            "            Conv2d-9         [512, 384, 13, 13]       1,327,488\n",
            "             ReLU-10         [512, 384, 13, 13]               0\n",
            "           Conv2d-11         [512, 256, 13, 13]         884,992\n",
            "             ReLU-12         [512, 256, 13, 13]               0\n",
            "        MaxPool2d-13           [512, 256, 6, 6]               0\n",
            "           Linear-14                [512, 4096]      37,752,832\n",
            "           Linear-15                [512, 4096]      16,781,312\n",
            "           Linear-16                  [512, 10]          40,970\n",
            "================================================================\n",
            "Total params: 58,299,082\n",
            "Trainable params: 58,299,082\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 100.64\n",
            "Forward/backward pass size (MB): 5589.16\n",
            "Params size (MB): 222.39\n",
            "Estimated Total Size (MB): 5912.20\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train 정의"
      ],
      "metadata": {
        "id": "Z0GHsipnSqpr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, device, train_loader, optimizer, epoch):\n",
        "    model.train()\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        # enumberate() : 인덱스와 원소로 이루어진 튜플(tuple)을 만들어줌\n",
        "        target = target.type(torch.LongTensor)\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad() # 항상 backpropagation 하기전에 미분(gradient)을 zero로 만들어주고 시작해야 한다.\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target) # criterion = loss_fn\n",
        "        loss.backward() # Computes the gradient of current tensor w.r.t. graph leaves\n",
        "        optimizer.step() # step() : 파라미터를 업데이트함\n",
        "        if (batch_idx + 1) % 30 == 0:\n",
        "            print(\"Train Epoch:{} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\".format(\n",
        "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                100. * batch_idx / len(train_loader), loss.item()))"
      ],
      "metadata": {
        "id": "ZD9j8ec_Sl67"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test 정의"
      ],
      "metadata": {
        "id": "JPyMVUzBSsW8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test(model, device, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += criterion(output, target, reduction='sum').item()\n",
        "            pred = output.max(1, keepdim=True)[1]\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "        test_loss /= len(test_loader.dataset)  # -> mean\n",
        "        print(\"\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n\".format(\n",
        "            test_loss, correct, len(test_loader.dataset), 100. * correct / len(test_loader.dataset)))\n",
        "        print('='*50)"
      ],
      "metadata": {
        "id": "oXKtOpBGSl9g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(1, epochs+1):\n",
        "    train(model, device, training_loader, optimizer, epoch)\n",
        "    test(model, device, validation_loader)"
      ],
      "metadata": {
        "id": "NkS1_3WaSl_9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}